{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN2018 - 1 - [Class Exercise] Linear Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamedmx/deep-learning-notes/blob/master/CNN2018_1_%5BClass_Exercise%5D_Linear_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4GgVIEOx63V",
        "colab_type": "text"
      },
      "source": [
        "![title](https://image.ibb.co/erDntK/logo2018.png)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_ChrQTZyAZU",
        "colab_type": "text"
      },
      "source": [
        "# [UNGRADED] Linear Classification Example\n",
        "\n",
        "with an `x` of 9 dimension, and 3 class target classification, so we have a weight parameter `w` with the size of (9,3) and bias `b` of size (3,)\n",
        "\n",
        "![Linear Classifier](https://image.ibb.co/iCvLL9/01.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFg7kihP1o8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "\n",
        "\n",
        "X = np.array([[59, 73, 24], [53, 71, 84], [46,  -5,  2]])\n",
        "print(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy7RoOyC1o8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = X.ravel()\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDXhnKRb1o8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = np.array([[ 0.06,  0.75, -0.64,  1.53, -1.37, -0.04, -1.11, -3.32, -0.91],\n",
        "              [-0.87,  2.69,  0.51,  2.28, -1.19,  0.36, -0.11, 0.78, -2.25],\n",
        "              [ 0.31, -0.03,  0.00,  0.27,  0.06,  0.28,  0.45, -1.46,  0.51]])\n",
        "\n",
        "print(W)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO-usHpd1o8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b = np.array([-1.5, 2.7, 0.1])\n",
        "\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjEKqz6-1o80",
        "colab_type": "text"
      },
      "source": [
        "calculate the scores using\n",
        "\n",
        "`scores = w*x+b`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu9nPwrf1o82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = W.dot(x.T) + b\n",
        "print('scores =',score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpGyIhmV1o86",
        "colab_type": "text"
      },
      "source": [
        "# [UNGRADED] Loss Example\n",
        "\n",
        "there are 2 popular Loss Functions that are often use:\n",
        "- Multiclass SVM Loss (Hinge Loss)\n",
        "- Softmax Loss (Cross Entropy Loss)\n",
        "\n",
        "for example, using the same score result calculate each loss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrMzQDan1o87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = np.array([0, 1, 2])\n",
        "num_data = 3\n",
        "num_class = 3\n",
        "\n",
        "\n",
        "scores = np.array(\n",
        "    [[ 3.2,  5.1, -1.7],    # scores for image cat\n",
        "     [ 1.3,  4.9,  2. ],    # scores for image dog\n",
        "     [ 2.2,  2.5, -3.1]])   # scores for image ship\n",
        "\n",
        "print(scores.T)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FEn4tbF1o9D",
        "colab_type": "text"
      },
      "source": [
        "# [UNGRADED] Multiclass SVM Loss Example\n",
        "\n",
        "\n",
        "![SVM Loss](https://image.ibb.co/eOkLL9/02.png)\n",
        "\n",
        "get score and the correct score for an input, for example for input `i=1`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGKxchOv1o9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = 2\n",
        "\n",
        "print('score image',img,'      =', scores[img])\n",
        "print('score on true class =', scores[img, y[img]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaEzX6l-1o9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = 1\n",
        "\n",
        "print('(score image',img,') minus (score on true class) =', scores[img]-scores[img, y[img]])\n",
        "print('margin is added by 1                         =', scores[img]-scores[img, y[img]]+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnfreV8n1o9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = 0\n",
        "\n",
        "margin = scores[img]-scores[img, y[img]] + 1\n",
        "print('remove all negative loss',img, '=', np.maximum(0, margin ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9Jgvill1o9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = 0\n",
        "\n",
        "margin = scores[img]-scores[img, y[img]] + 1\n",
        "losses_i = np.maximum(0, margin)\n",
        "print('loss of example',img, '(Li) is the sum of it, minus 1 (target) =', np.sum(losses_i) - 1 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMPwmZiP1o9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Hinge Loss or Multiclass SVM Loss is the average of all example losses')\n",
        "\n",
        "Loss = 0\n",
        "\n",
        "num_data = 3\n",
        "for img in range(num_data):\n",
        "    margin = scores[img]-scores[img, y[img]] + 1\n",
        "    losses_i = np.maximum(0, margin)\n",
        "    L_i = np.sum(losses_i) - 1\n",
        "    print(L_i)\n",
        "    Loss += L_i\n",
        "\n",
        "Loss /= num_data\n",
        "\n",
        "print('SVM Loss =', Loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaC7u7NE1o9i",
        "colab_type": "text"
      },
      "source": [
        "# [UNGRADED] Softmax Loss Example\n",
        "\n",
        "![Softmax Loss](https://image.ibb.co/msQy7p/03.png)\n",
        "\n",
        "using the same initial score, to calculate Softmax Loss, first it's better to subtract the loss by maximum score for each class to attain numerical stability\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3JvVrSu1o9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(scores.T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnyDE3w81o9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "e_scores = np.exp(scores)\n",
        "print(e_scores.T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pFVJynB1o9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum_e_score = np.sum(e_scores, axis=1, keepdims = True)\n",
        "print(sum_e_score.T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhI7HJNe1o9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "norm_log_prob = e_scores / sum_e_score\n",
        "print(norm_log_prob.T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVu3S4ov1o90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = 0\n",
        "\n",
        "print('probability over all classes on image', img, '      =', norm_log_prob[img])\n",
        "print('total probability over all classes on image', img, '=', np.sum(norm_log_prob[img]))\n",
        "print('this is the softmax score')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuyurZpi1o97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(norm_log_prob.T)\n",
        "loss_i = -np.log10(norm_log_prob)\n",
        "print(loss_i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTgvHfF81o9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(norm_log_prob.T)\n",
        "loss_i_natural = -np.log(norm_log_prob)\n",
        "print(loss_i_natural)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFF-a7r71o-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Softmax Loss is the average of all example losses')\n",
        "\n",
        "Loss = 0\n",
        "\n",
        "num_data = 3\n",
        "for img in range(num_data):\n",
        "    Loss += loss_i[img,y[img]]\n",
        "\n",
        "Loss /=3\n",
        "print('Softmax Loss =', Loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb_cSaN61o-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Softmax Loss is the average of all example losses, Natural Log')\n",
        "\n",
        "Loss_natural = 0\n",
        "\n",
        "num_data = 3\n",
        "for img in range(num_data):\n",
        "    Loss_natural += loss_i_natural[img,y[img]]\n",
        "\n",
        "Loss_natural /=3\n",
        "print('Softmax Loss =', Loss_natural)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlzKCxIF1o-P",
        "colab_type": "text"
      },
      "source": [
        "## Practical Issues: Shift Score to reduce computation workload"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFebKLfh1o-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shifted_scores = scores - np.max(scores)\n",
        "print(shifted_scores.T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxDk1kCs1o-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "e_shifted_scores = np.exp(shifted_scores)\n",
        "print(e_shifted_scores.T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjNLTu7D1o-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum_e_shifted_score = np.sum(e_shifted_scores, axis=1, keepdims = True)\n",
        "norm_log_prob_shifted = e_shifted_scores / sum_e_shifted_score\n",
        "loss_i_shifted = -np.log10(norm_log_prob_shifted)\n",
        "\n",
        "\n",
        "Loss_shifted = 0\n",
        "\n",
        "num_data = 3\n",
        "for img in range(num_data):\n",
        "    Loss_shifted += loss_i_shifted[img,y[img]]\n",
        "\n",
        "Loss_shifted /=3\n",
        "print('Softmax Loss =', Loss)\n",
        "print('Softmax Loss Shifted =', Loss_shifted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqhn3S3Ex8me",
        "colab_type": "text"
      },
      "source": [
        "![footer](https://image.ibb.co/hAHDYK/footer2018.png)"
      ]
    }
  ]
}